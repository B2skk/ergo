{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Performance And Costing Analysis of Ergo Node\n",
    "\n",
    "## Introduction\n",
    "This notebook uses `Metrics.sqlite` database collected during full node syncronization.\n",
    "See `README.md` for detail of database schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n",
    "If necessary uncomment and run the following commands to setup necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify one nbextension/package at a time\r\n"
     ]
    }
   ],
   "source": [
    "#!pip install ipython-sql\n",
    "#!pip install jupyter_contrib_nbextensions\n",
    "#!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable python-markdown / main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# open sqlite connection to perform queries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"../Metrics.sqlite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## v5.0 Validation\n",
    "- make sure validateTxStateful recorded for each transaction of the block (should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "    -- invalid tx_num\n",
    "    select b.blockId, t.tx_count as c, b.tx_num as n\n",
    "    from (select blockId, count(*) as tx_count\n",
    "          from validateTxStateful\n",
    "          group by blockId) as t\n",
    "             join applyTransactions as b on b.blockId = t.blockId\n",
    "    where c != n;\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- make sure recored block cost = sum of recorded tx costs (should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "    -- invalid tx cost\n",
    "    select b.blockId, t.sum_costs as sum_tx_costs, b.cost as block_cost\n",
    "    from (select blockId, sum(cost) as sum_costs\n",
    "          from validateTxStateful\n",
    "          group by blockId) as t\n",
    "             join applyTransactions as b on b.blockId = t.blockId\n",
    "    where sum_tx_costs != block_cost;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- now many transactions have negative cost (should be empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "-- count tx with negative cost\n",
    "select count(*)\n",
    "from validateTxStateful\n",
    "where cost < 0;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "variables": {
     " ok ": "ok",
     "-ok-": "<p><strong>SyntaxError</strong>: invalid syntax (<ipython-input-12-7b1f9aef2133>, line 1)</p>\n"
    }
   },
   "source": [
    "## v5.0 Analysis\n",
    "### Block Validation Time Analysis\n",
    "In this section we compare script validation time against block validation time.\n",
    "\n",
    "#### Sizes of the recorded tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "    select * from\n",
    "    (select count(*) as appendFullBlock\n",
    "    from appendFullBlock),\n",
    "    (select count(*) as applyTransactions\n",
    "    from applyTransactions),\n",
    "    (select count(*) as createUtxoState\n",
    "    from createUtxoState),\n",
    "    (select count(*) as validateTxStateful\n",
    "    from validateTxStateful),\n",
    "    (select count(*) as verifyScript\n",
    "    from verifyScript)\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparing Stages of Block Validation\n",
    "First we look at how much time of the total block validation is spent in applyTransactions.\n",
    "We group and count blocks by (total time / `applyTransactions` time) ratio.\n",
    "We see that `applyTransactions` is < 50% for roughly 80% of the blocks.\n",
    "For more ~40% of the blocks:\n",
    "1) the ratio is above 3, which means script validation is < 33%\n",
    "2) further analysis shows that time is spent in creating UtxoState (after applyTransaction)\n",
    "**Thus, creating UtxoState after application of transactions requires profiling and optimization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select time_us / t2_us as time_ratio, count(*) as block_count\n",
    "from (select b1.blockId,\n",
    "             b1.height,\n",
    "             b1.tx_num,\n",
    "             b2.cost,\n",
    "             b1.time / 1000                       as t1_us,\n",
    "             b2.time / 1000                       as t2_us,\n",
    "             b3.time / 1000                       as t3_us,\n",
    "             (b1.time + b2.time + b3.time) / 1000 as time_us\n",
    "      from appendFullBlock as b1\n",
    "               join applyTransactions as b2 on b1.blockId = b2.blockId\n",
    "               join createUtxoState b3 on b1.blockId = b3.blockId)\n",
    "group by time_ratio\n",
    "order by time_ratio;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Comparing applyTransaction of block with validateTxStateful\n",
    "Here we further drill down to applyTransactions part of block validation.\n",
    "Specifically, for each block we compare the time of `UtxoState.applyTransactions` with total time\n",
    "of `ErgoTransaction.validateStateful` taken for all transactions in the block.\n",
    "The blocks are grouped by the ratio between times.\n",
    "We can see that for > 70% blocks the ration is above 2, which suggests that\n",
    "**`UtxoState.applyTransactions` method need optimizations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select t.time_ratio / 10 as time_ratio,\n",
    "       count(*) as block_count,\n",
    "       round(avg(t.block_time_us), 0)  as avg_block_time_us,\n",
    "       round(avg(t.tx_time_us), 0) as avg_tx_time_us,\n",
    "       round(avg(t.tx_count), 1)   as avg_tx_count\n",
    "from (select b.blockId,\n",
    "             tx.tx_count,\n",
    "             b.time / 1000                        as block_time_us,\n",
    "             tx.sum_tx_time / 1000            as tx_time_us,\n",
    "             (b.time - tx.sum_tx_time) / 1000 as time_diff_us,\n",
    "             b.time * 10 / tx.sum_tx_time     as time_ratio\n",
    "      from (select blockId,\n",
    "                   sum(time) as sum_tx_time,\n",
    "                   count(*)  as tx_count\n",
    "            from validateTxStateful\n",
    "            group by blockId) as tx\n",
    "               join applyTransactions as b on b.blockId = tx.blockId) as t\n",
    "group by t.time_ratio / 10\n",
    "order by t.time_ratio / 10;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tx/Script validation time ratio\n",
    "Further down to validation call stack, we observe how much `validateStateful` time larger than\n",
    "script verification time.\n",
    "The ratio is computed for each transaction and then the transactions are grouped by integer ratio.\n",
    "Comparing times in `verifyScript` and `validateTxStateful` metrics.\n",
    "We see that for most transactions, `verifyScript` is > 50% of `validateStateful`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select t.time_ratio / 10 as time_ratio,\n",
    "       count(*) as tx_count,\n",
    "       round(avg(t.tx_time_us), 1) as avg_tx_time_us,\n",
    "       round(avg(t.script_time_us), 1) as avg_script_time_us,\n",
    "       round(avg(t.script_count), 1) as avg_script_count\n",
    "from (select tx.blockId,\n",
    "             tx.txId,\n",
    "             t.script_count,\n",
    "             tx.time / 1000                   as tx_time_us,\n",
    "             t.sum_script_time / 1000         as script_time_us,\n",
    "             tx.time * 10 / t.sum_script_time as time_ratio\n",
    "      from (select blockId,\n",
    "                   txId,\n",
    "                   sum(time) as sum_script_time,\n",
    "                   count(*)  as script_count\n",
    "            from verifyScript\n",
    "            group by blockId, txId) as t\n",
    "               join validateTxStateful as tx on tx.blockId = t.blockId and tx.txId = t.txId) as t\n",
    "group by t.time_ratio / 10\n",
    "order by t.time_ratio / 10;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to further drill down inside the mose populated group.\n",
    "We build a detailed grouping of the transactions where the ratio <= 1.9,\n",
    "comparing times in `verifyScript` and `validateTxStateful` metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select round(t.time_ratio * 0.1, 1) as time_ratio,\n",
    "       count(*) as tx_count,\n",
    "       round(avg(t.tx_time_us), 1) as avg_tx_time_us,\n",
    "       round(avg(t.script_time_us), 1) as avg_script_time_us,\n",
    "       round(avg(t.script_count), 1) as avg_script_count\n",
    "from (select tx.blockId,\n",
    "             tx.txId,\n",
    "             t.script_count,\n",
    "             tx.time / 1000                   as tx_time_us,\n",
    "             t.sum_script_time / 1000         as script_time_us,\n",
    "             tx.time * 10 / t.sum_script_time as time_ratio\n",
    "      from (select blockId,\n",
    "                   txId,\n",
    "                   sum(time) as sum_script_time,\n",
    "                   count(*)  as script_count\n",
    "            from verifyScript\n",
    "            group by blockId, txId) as t\n",
    "               join validateTxStateful as tx on tx.blockId = t.blockId and tx.txId = t.txId) as t\n",
    "where t.time_ratio <= 19\n",
    "group by t.time_ratio\n",
    "order by t.time_ratio;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count transactions where script validation <= 80% of `validateStatefull`.\n",
    "This DOESN'T show big potential for optimizing `validateStateful` outside script evaluation.\n",
    "Comparing times in `verifyScript` and `validateTxStateful` metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select count(*) as tx_count\n",
    "from (select tx.blockId,\n",
    "             tx.txId,\n",
    "             t.script_count,\n",
    "             tx.time / 1000                   as tx_time_us,\n",
    "             t.sum_script_time / 1000         as script_time_us,\n",
    "             tx.time * 10 / t.sum_script_time as time_ratio\n",
    "      from (select blockId,\n",
    "                   txId,\n",
    "                   sum(time) as sum_script_time,\n",
    "                   count(*)  as script_count\n",
    "            from verifyScript\n",
    "            group by blockId, txId) as t\n",
    "               join validateTxStateful as tx on tx.blockId = t.blockId and tx.txId = t.txId) as t\n",
    "where t.time_ratio >= 12;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Conclusions:\n",
    "- Creating UtxoState after application of transactions requires profiling and optimization.\n",
    "- `UtxoState.applyTransactions` method need optimizations.\n",
    "- In most of the cases the time to validate transaction (`validateStateful` method) is dominated by\n",
    "the script validation time\n",
    "- There is a few transactions where script validation not greater than 80% of tx validation time.\n",
    "- The results suggest that `validateStateful` doesn't require optimizations, or at least it can\n",
    "be done after the other parts of block validation had been optimized.\n",
    "\n",
    "## v5.0 vs v4.0 Cross Analysis\n",
    "\n",
    "### Cross Version validation\n",
    "- Make sure recorded data for v5 and v4 have the same `height` and `tx_num` for all blockIds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "checks = dict(\n",
    "    appendFullBlockOk=pd.read_sql_query(f\"\"\"\n",
    "        -- validate appendFullBlock tables\n",
    "        select *\n",
    "        from appendFullBlock a1\n",
    "                 join appendFullBlock4 a2 on a1.blockId = a2.blockId\n",
    "        where a1.height != a2.height\n",
    "           or a1.tx_num != a2.tx_num;\n",
    "        \"\"\", conn).size == 0,\n",
    "    applyTransactionsOk=pd.read_sql_query(f\"\"\"\n",
    "        select *\n",
    "        from applyTransactions a1\n",
    "                 join applyTransactions4 a2 on a1.blockId = a2.blockId\n",
    "        where a1.height != a2.height\n",
    "           or a1.tx_num != a2.tx_num;\n",
    "        \"\"\", conn).size == 0,\n",
    "    createUtxoStateOk=pd.read_sql_query(f\"\"\"\n",
    "        select *\n",
    "        from createUtxoState a1\n",
    "                 join createUtxoState4 a2 on a1.blockId = a2.blockId\n",
    "        where a1.height != a2.height\n",
    "           or a1.tx_num != a2.tx_num;\n",
    "        \"\"\", conn).size == 0\n",
    ")\n",
    "if not (checks.get(\"appendFullBlockOk\") and checks.get(\"applyTransactionsOk\") and checks.get(\n",
    "        \"createUtxoStateOk\")):\n",
    "    ok = checks\n",
    "else:\n",
    "    ok = \"ok\"\n",
    "print(checks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block Validation Times\n",
    "First count recorded block validations of v4 and v5 and how much of them can be\n",
    "joined. This is also validation check, because `common_rows` should be equal to the minimal count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select *, count_rows5 - count_rows4 as v5_v4_rows_diff\n",
    "from (select count(*) as count_rows5 from applyTransactions),\n",
    "     (select count(*) as count_rows4 from applyTransactions4),\n",
    "     (select count(*) as common_rows\n",
    "      from applyTransactions as t5 join applyTransactions4 t4 on t5.blockId = t4.blockId);\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The new v5 script interpreter is expected to perform faster comparing to v4.\n",
    "The following shows the distribution of the blocks across ranges of speedup. We see that for the\n",
    "most of the blocks the speedup is in a range from 1 (no speedup) to 2 (twice faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select t4.time / t5.time as speedup, count(*) as num_blocks\n",
    "from applyTransactions t5 join applyTransactions4 t4 on t5.blockId = t4.blockId\n",
    "group by speedup order by speedup;\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We see outliers, i.e. blocks which executed slower in v5 than in v4. This can be attributed to\n",
    "measurement fluctuations. Such blocks will be simply filtered out in the following analysis.\n",
    "\n",
    "We also see a long tail of blocks with higher than 2 speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select sum(num_blocks) from (\n",
    "select t4.time / t5.time as speedup, count(*) as num_blocks\n",
    "from applyTransactions t5 join applyTransactions4 t4 on t5.blockId = t4.blockId\n",
    "where speedup >= 2\n",
    "group by speedup order by speedup\n",
    ")\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see how the speedup is spread over ranges of the blockchain.\n",
    "The block `b` falls in `range` if `range = b.height / 100000`. The blocks of each range are counted,\n",
    "and the average speedup over the range is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select t5.height / 100000                            as range,\n",
    "       round(avg(t4.time * 100 / t5.time * 0.01), 2) as avg_speedup,\n",
    "       count(*)                                      as num_blocks\n",
    "from applyTransactions t5 join applyTransactions4 t4 on t5.blockId = t4.blockId\n",
    "where t4.time / t5.time >= 1\n",
    "group by range order by range;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We observe that the average speedup increase towards the most recent range, which is expected, because\n",
    "more and more complex contracts are used on chain over time. The v5 script interpreter is by design\n",
    "faster on complex contracts.\n",
    "\n",
    "If we further constrain speedup to be above 1.2, we get the following distribution of blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select t5.height / 100000                            as range,\n",
    "       round(avg(t4.time * 100 / t5.time * 0.01), 2) as avg_speedup,\n",
    "       count(*) as num_blocks\n",
    "from applyTransactions t5 join applyTransactions4 t4 on t5.blockId = t4.blockId\n",
    "where t4.time * 100 / t5.time * 0.01 >= 1.2\n",
    "group by range order by range\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Note, this speedups are due to improvements in script evaluation which is further analyzed in the\n",
    "[next section](#script-validation-time). However, as shown in [Comparing Stages of Block\n",
    "Validation](#comparing-stages-of-block-validation), for most of the blocks, script evaluation is\n",
    "less than 50% of the block validation time, so the impact of script speedups is limited by this\n",
    "factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Script Validation Time\n",
    "In this section we focus on script evaluation part only (i.e. Interpreter.verify method), which is\n",
    "measured and recorded in `verifyScript` table.\n",
    "\n",
    "First count recorded script validations of v4 and v5 and how much of them can be\n",
    "joined. This is also validation check, because `common_rows` should be equal to the minimal count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select *, total_rows5 - total_rows4 as v5_v4_rows_diff from\n",
    "(select count(*) as total_rows5\n",
    "from verifyScript as s),\n",
    "(select count(*) as total_rows4\n",
    "from verifyScript4 as s),\n",
    "(select count(*) as common_rows\n",
    "from verifyScript as t5 join verifyScript4 t4\n",
    "  on t5.blockId = t4.blockId and t5.txId = t4.txId and t5.boxIndex = t4.boxIndex);\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "  For common recorded script we compute the total time spend in script validation for both v4 and v5\n",
    "  and compare them. Then compute the expected percent of total script time reduction after switching\n",
    "  to v5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select times.total_time4 / 1000                                   as total_time4_us,\n",
    "       times.total_time5 / 1000                                   as total_time5_us,\n",
    "       (times.total_time4 - times.total_time5) / 1000             as total_diff_us,\n",
    "       round((1 - round(times.total_time5 * 100 / times.total_time4 * 0.01, 1)) * 100, 1) as percent_of_reduction\n",
    "from (select sum(t5.time) as total_time5,\n",
    "             sum(t4.time) as total_time4\n",
    "      from verifyScript as t5\n",
    "               join verifyScript4 t4\n",
    "                    on t5.blockId = t4.blockId\n",
    "                        and t5.txId = t4.txId\n",
    "                        and t5.boxIndex = t4.boxIndex) as times;\n",
    "\"\"\", conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Block Validation Cost Analysis\n",
    "In this section we compare block validation costs against block validation time in order to see how\n",
    "accurate cost estimation predicts the actual execution time.\n",
    "\n",
    "The validation complexity is estimated in cost units, one cost unit corresponds approximately to\n",
    "1 microsecond of execution time, thus when cost is 1000 then execution time is expected to be 1000\n",
    "microseconds.\n",
    "\n",
    "Since cost predition is a security measure, we want to be conservative and require that for most\n",
    "blocks the predicted cost is larger than execution time in microseconds.\n",
    "\n",
    "The following table counts blocks with execution time exceeding predicted cost. The blocks are\n",
    "grouped by `time / cost` ratio. We see that in v4.x only 50 blocks were validated longer than\n",
    "predicted. The one outlier block is measurement artefact and can be ignored.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "-- find blocks where cost is less than time_us\n",
    "select min(ratio / 10) as ratio, count(*)\n",
    "from (select height,\n",
    "             tx_num,\n",
    "             cost,\n",
    "             time / 1000          as time_us,\n",
    "             (time / 1000) * 10 / cost as ratio\n",
    "      from applyTransactions4\n",
    "      where time_us > cost)\n",
    "group by ratio / 10\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "The same query with v5.0 execution data shows similar results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "-- find blocks where cost is less than time_us\n",
    "select min(ratio / 10) as ratio, count(*)\n",
    "from (select height,\n",
    "             tx_num,\n",
    "             cost as full_cost,\n",
    "             time / 1000          as time_us,\n",
    "             (time / 1000) * 10 / cost as ratio\n",
    "      from applyTransactions\n",
    "      where time_us > full_cost)\n",
    "group by ratio / 10\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can conclude that both v4.x and v5.0 costing can be used as the upper bound of the actual block\n",
    "validation time, i.e. for most of the blocks the cost value is larger than execution time in\n",
    "microseconds. How accurate this bound?\n",
    "\n",
    "In v4.x the `cost / time` ratio is in [20 .. 70) range which is quite conservative, leaving a lot of\n",
    "room for improvement."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "-- group and count blocks by cost/time ratio (v4)\n",
    "select min(ratio), count(*), round(avg(tx_num), 2) as avg_tx_num\n",
    "from (select height,\n",
    "             tx_num,\n",
    "             cost as full_cost,\n",
    "             time / 1000          as time_us,\n",
    "             cost / (time / 1000)  as ratio\n",
    "      from applyTransactions4\n",
    "      where time_us <= full_cost)\n",
    "group by ratio / 10\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indeed, as can be seen in the following table, in v5.0 cost prediction is significantly improved so\n",
    "that the `cost / time` ratio is in [1 .. 19) range for most blocks.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "-- group and count blocks by cost/time ratio (v5)\n",
    "select min(ratio), count(*), round(avg(tx_num), 2) as avg_tx_num\n",
    "from (select height,\n",
    "             tx_num,\n",
    "             cost as full_cost,\n",
    "             time / 1000          as time_us,\n",
    "             cost / (time / 1000)  as ratio\n",
    "      from applyTransactions\n",
    "      where time_us <= full_cost)\n",
    "group by ratio / 10\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The maximal cost of each block is limited by maxBlockCost parameter stored in block parameters\n",
    "section of each block. This parameter can be changed by miners via voting. The following table shows\n",
    "the distribution of blocks over range of cost limits.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select min(maxCost), count(*) from applyTransactions\n",
    "group by maxCost / 1000000\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see the cost limit significantly increased by the miners (in fact by the pool operators) from\n",
    "initial 1000000 up to 7030268 current value.\n",
    "\n",
    "Now that we have cost limits for each block, let's see how far the actual block validation costs\n",
    "from that limits.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select maxCost / cost as ratio, count(*), min(height) from applyTransactions\n",
    "group by ratio\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see that for all blocks the actual cost is at least 2x less then cost limit. However, we also see\n",
    "that for many blocks the cost is much smaller (569 times) than the limit value .\n",
    "Lets investigate further the blocks with lowest and highest ratios.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select round(maxCost * 10 / cost * 0.1, 1) as ratio, count(*), min(height) from applyTransactions\n",
    "where ratio <= 3\n",
    "group by ratio\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is the block with lowest ratio?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select round(t5.maxCost * 10 / t5.cost * 0.1, 1) as ratio,\n",
    "       t5.height, t5.tx_num, t5.maxCost,\n",
    "       t5.cost as cost_v5,\n",
    "       t5.time / 1000 as time_t5_us,\n",
    "       7030268 / (t5.time / 1000) as scalability_v5,\n",
    "       t4.cost as cost_v4,\n",
    "       t4.time / 1000 as time_t4_us\n",
    "from applyTransactions t5\n",
    "         join applyTransactions4 t4 on t5.blockId = t4.blockId\n",
    "where ratio < 2.6\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the block deep in the blockchain with 114 transactions.\n",
    "Note, the v4 cost hit the cost limit, so this number of transaction was maximum possible at that\n",
    "time. This is a good example to illustrate the benefits of v5.0. Not only it executed the same\n",
    "transaction slightly faster, but also due to more accurate costing, the predicted cost is 2.5 times\n",
    "lower than v4 cost. This means the operator would have been able to include more than 300\n",
    "transactions in the block thus increasing network throughput and reduce congestion.\n",
    "\n",
    "Since then, the cost limit was increased by pool operators up to 7030268, almost 2x.\n",
    "Using these numbers we can roughly estimate the number of transactions in a block as\n",
    "114 * (7030268(maxCost) / 1947948(cost_v5)) = 411 transactions.\n",
    "\n",
    "We can also estimate the potential scalability of v5.0 if we compare the actual execution time with\n",
    "the current cost limit (see `scalability_v5`). With further tuning of the cost parameters (possible\n",
    "via voting) the number of such transactions in one block can be 114 * 100 = 11400 (even with the\n",
    "current unoptimized state management), or 11400 / 120 = 95 tx/second.\n",
    "\n",
    "At the same time, in this case, the total block validation would take 70212 * 100 = 7021200\n",
    "microseconds, which is above the recommended time limit of 5 seconds. This suggest that _pool\n",
    "operators need to postpone further increasing of the maxBlockCost parameter and instead switch on to tuning\n",
    "the cost parameters to make the cost prediction more accurate_.\n",
    "\n",
    "Now, what about the other side of the maxCost/cost ratio spectrum, where cost limit is much larger\n",
    "than the actual block cost.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.read_sql_query(f\"\"\"\n",
    "select round(maxCost * 10 / cost * 0.1, 1) as ratio,\n",
    "       height, tx_num, maxCost, cost,\n",
    "       time / 1000                         as time_us\n",
    "from applyTransactions\n",
    "where ratio >= 569\n",
    "order by height desc\n",
    "limit 20\n",
    "\"\"\", conn)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see many recent blocks (the highest `height`) with single simple transaction.\n",
    "\n",
    "#### Conclusions\n",
    "What this analysis of actual execution of Ergo Node v5.0 tell us:\n",
    "- the new cost estimation is properly estimates the actual execution time of all the existing\n",
    "blocks.\n",
    "- the cost estimation is reasonably conservative, i.e. for 95% blocks it overestimates the actual\n",
    "costs, but this overestimation is significantly lower than in v4.x\n",
    "- for all blocks the estimated costs are more than 2.5 times lower than the cost limits.\n",
    "- In the low boundary case shown above, the block which is the closest to the cost limit has 100+\n",
    "transactions. With v5.0 this number could be higher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}